# 特征工程的基础原则

* 特征的本质是对某个行为过程相关信息的抽象表达，将行为序列数据转换为数学形式，从而让机器学习模型所学习，这个过程就叫做特征工程；

# 常见特征工程清洗方法

## 连续型特征

* 案例：年龄、统计类特征、物料的发布时间、播放时长等数值型特征
* 处理手段：归一化/离散化/加非线性函数等方法。
  * 归一化:统一各特征的量纲，将连续特征归一到(0,1]区间，也可以做0均值归一化，将原始数据集归一化为均值0、方差为1的数据集；
  * 离散化:通过确定分位数的形式将原来的连续值进行分桶，最终形成离散值的过程。离散化主要目的是防止连续值带来的过拟合现象及特征值分布不均匀情况；经过离散化处理的连续型特征和经过one-hot
    处理的类别型特征一样都是以向量的形式输入推荐模型中；
  * 加非线性函数:通过非线性转换，把原来的特征及变化后的特征一起加入模型进行训练。常用非线性函数包括x的a次方，loga(x)，log(x/1-x)。

## 类别型特征

* 案例:用户的历史行为数据、属性标签类数据等。
* 处理手段: one-hot、multi-hot
  * one-hot: 将类别型特征转换为向量的一种编码方式，例如有三个特征星期、性别、城市用[weekday=tuesday,gender=male,city=london]
    来表示，由于模型输入向量仅可以使数值型，所以可以将上述类别特征做one-hot编码。weekday有七个维度可以表示为[0,1,0,0,0,0,0]，gender有2个维度可以表示为[0,1]，city同理；
  * multi-hot:用户往往会与多个物品产生交互行为，或者被打上多个同类别标签，这是可以通过multi-hot进行编码。例如共有10000个物料数据，其中用户点击了10个，那么可以转换为一个10000维的向量，其中仅有10
    个已点击的维度是1，其余都是0。
* 问题:对类别特征进行one-hot或multi-hot编码会导致特征向量维度过大，特征过于稀疏，容易造成模型欠拟合，模型的权重参数的数量过多，导致模型收敛过慢。因此现阶段对于类别型特征主要使用稠密Embedding
  向量，再与其他特征组合，形成最终的输入特征向量。